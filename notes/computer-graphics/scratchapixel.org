#+TITLE: Notes from the [[http://scratchapixel.com][scratchapixel.com]]

* Introduction to Ray Tracing: a Simple Method for Creating 3D Images
** How does it work?
*** What are the steps of creating a 2d image of a 3d scene?
- Perspective Projection
  - Projecting the 3d image onto an image plane
- Light and Color
  - What is light made of? Photons
  - What are the components of photons? They are electromagnetic, so they have an electric and a magnetic component
  - If light hits an object, what three things can happen to it? It can either be reflected, absorbed or transmitted
  - What do all materials have in common? The number of incoming photons is equal to the sum of photons reflected, absorbed or transmitted
  - What are the two types of metal materials? Conductors and dielectrics
  - What are some examples of dielectrics? Glass, water, wood, plastic, etc.
  - Why does an object appear a certain color? Let's take the example of a red ball. If a white light is illuminating it (a white light consists of red, green and blue photons) the red ball will absorb the red and green components and reflect the red light. The object appears red because our eye catches the red photons that the ball reflects
** Raytracing Algorithm in a Nutshell
*** What, in simple terms, is forward ray-tracing?
- Following the path of a photon (or many photons) from the light source to the observer (the eye or an image plane)
- Why is forward ray-tracing problematic, especially in the realm of the constraints on modern computers? In terms of probability, there are very few photons that will be emitted from a light source and actually fall onto the image plane (or eye). Thus, potentially there are many wasted operations and calculations that are completed
*** What, in simple terms, is backwards ray-tracing?
- It's quite simply the opposite of forward ray-tracing. Instead of tracing every single photon/ray from the light source, we trace rays from the eye back to the light source and keep the ones that actually reach it
- When using backwards ray-tracing, what rays do we "keep" and what are they called? When we shoot a ray from the eye, if it reaches the object, we shoot another ray from that object (which follows the geometry/material construction of that object) and see if it hits the light source. This ray is called a light or shadow ray
- If the ray that gets reflected from the object then intersects another object before hitting the light, what kind of ray is it? In this case, it's technically a shadow ray since it's in the objects shadow
- What are the rays that get emitted from the eye called? Primary ray, visibility ray or camera ray
- What is path tracing? The process of either casting rays from the light source or from the eye/camera
*** Sometimes, an author may refer to forward ray-tracing when they are referring to backwards ray-tracing. You can determine this usually by the type of ray they are referring to. If they are talking about the primary ray or camera ray, they are actually talking about backwards ray-tracing
** Implementing the Raytracing Algorithm
*** Describe the raytracing algorithm in basic terms
- Step 1. For each pixel, shot a ray from the eye that intersects the pixel's center
- Step 2. Find what object the ray intersects in the scene. If it intersect multiple objects, use the closest one
- Step 3. Shoot a shadow ray from the object the ray intersected to see if it reaches the light source. If it does, the point the eye ray intersected is illuminated by the light. If not, the object that the eye ray intersected is in the shadow of the object that the shadow ray intersected. Repeat for all eye rays
*** What are some other ray geometry intersection algorithms?
- Scanline renderer and the z-buffer algorithm
*** Who, in 1969 in a paper entitled "Some Techniques for Shading Machine Renderings of Solids", first introduced the raytracing technique?
- Arthur Appel
*** Example source code for a simple raytracing algorithm[fn:1]
#+BEGIN_SRC
for (int j = 0; j < imageHeight; ++j) { 
    for (int i = 0; i < imageWidth; ++i) { 
        // compute primary ray direction
        Ray primRay; 
        computePrimRay(i, j, &primRay); 
        // shoot prim ray in the scene and search for intersection
        Point pHit; 
        Normal nHit; 
        float minDist = INFINITY; 
        Object object = NULL; 
        for (int k = 0; k < objects.size(); ++k) { 
            if (Intersect(objects[k], primRay, &pHit, &nHit)) { 
                float distance = Distance(eyePosition, pHit); 
                if (distance < minDistance) { 
                    object = objects[k]; 
                    minDistance = distance; // update min distance 
                    } 
            } 
        } 
        if (object != NULL) { 
            // compute illumination
            Ray shadowRay; 
            shadowRay.direction = lightPosition - pHit; 
            bool isShadow = false; 
            for (int k = 0; k < objects.size(); ++k) { 
                if (Intersect(objects[k], shadowRay)) { 
                    isInShadow = true; 
                    break; 
                } 
            } 
        } 
        if (!isInShadow) 
            pixels[i][j] = object->color * light.brightness; 
        else 
            pixels[i][j] = 0; 
    } 
} 
#+END_SRC
** Adding Reflection and Refraction
*** Who was the first to describe how to extend Appel's ray-tracing algorithm for more advanced rendering?
- Turner Whitted
*** What are reflection and refraction [ray] directions based on?
- The normal at the point of intersection and the direction of the incoming ray (primary ray)
*** To compute the refraction [ray] direction, what additional information do we need?
- The index of refraction (IOR) of the object being intersected
*** How, in general terms, do we determine how much of an incoming ray gets reflected and how much of it is refracted?
- Intuitively enough, it's not just a matter of splitting the difference between reflection and refraction. It is based on the look angle (the primary ray) and both the IOR and the normal of the object. Given that info, there's an equation to calculate everything and that equation is known as the Fresnel equation. More on this later
*** To recap, what three steps are involved in the Whitted equation (to determine the color of a point on an object with both refraction and reflection, like a glass ball for instance)
- Computer the reflection color, computer the refraction color and then apply the Fresnel equation
*** What is a transmission ray?
- When a ray hits an object with refractive properties, that ray will go through the object. That ray is then considered a transmission ray

* Where Do I Start? A Very Gentle Introduction to Computer Graphics Programming
** A Gentle Introduction To Computer Graphics Programming
*** What is foreshortening?
- Objects appearing smaller the farther away they are
*** What is stereoscopic vision?
- This is when our brain is able to use our two eyes with two slightly different angles of the views in front of it to create an image that we are able to approximate the distance to the objects in front of us
*** In CG, what is a scene?
- A scene is a collection of objects. Each object will have a set of coordinates that describe the object and its dimensions
*** What is topology?
- Topology refers to how points which we generally call vertices are connected to each other to form faces (or flat surfaces)
*** What is a viewing frustum?
- It's the pyramid that is created when drawing lines from the eye to the corners of the canvas as far as you need
*** In CG, what is the world coordinate system?
- It's really just the coordinate system that the whole scene or world uses. If you have three rulers (or axis) that form the three different dimensions, the intersection of those axis is the origin
*** What is the "default viewing system" for most 3d applications?
- If you move the apex of the viewing frustum to the origin of the world coordinate system and orient the line of sight to the negative z axis, that is what the "default viewing system" looks like
*** See image
[[file:box-setup4.png][box-setup4.png]] [fn:2]
*** What are similar triangles?
- Two triangles that have the same angle (between the hypotenuse and the adjacent edges). They also have another characteristic and that is that the ratio between the opposite and the adjacent edges between the two is equal. In the case of the image above that means this:

\[\frac{BC}{AB}=\frac{B\prime C\prime}{AB\prime}\] 

*** Because the canvas is 1 unit away from the origin, we know that AB' equals 1. We also know the position of B and C which are the z (depth) and y coordinates (height) respectively of the corner. If we substitute these numbers in the above equation, we get:

\[\frac{P\cdot y}{P\cdot z}=\frac{P\prime \cdot y}{1}\]

- Where y' is actually the y coordinate of the point where the line going from the corner to the viewpoint intersects the canvas, which is, was we said earlier, the dot from which we can draw an image of the box on the canvas. Thus:

\[P\prime \cdot y=\frac{P\cdot y}{P\cdot z}\]

- Given the above info, what is perspective divide?
  - In this example, it is simply the fact that projection of the y-coordinate of the corner on the canvas is the corner's y-coordinate divided by its depth (z-coordinate). The same principle applies to the x-coordinate

*** Since the z-coordinate (in this example and in many applications) is negative, the resulting x- and y-coordinate projected on the canvas will also be negative. To solve that, we simply reverse the sign of the z-coordinate. Here is the final x- and y-coordinates

- \[P\prime x=\frac{P\cdot x}{-P\cdot z}\]

- \[P\prime y=\frac{P\cdot y}{-P\cdot z}\]

*** The canvas we draw our 3d scene on is of an arbitrary size. Most computer screens aren't the same dimension, so it will be difficult to manipulate the points without knowing that in advance. What can be done to help remedy this situation?
- We simply normalize the points. We must convert the range of points possible on our arbitrary canvas to the range [0,1]
  - *Note*: I need to go back to this chapter to figure out what they are saying. In reading the tutorial on learnopengl.com it seems that normalized device coordinates (NDC) is between -1 and 1. Which if I remember correctly from reading this chapter, that's what the original coordinates the box in the scene was based on. I don't know, I'll come back to it
*** What is raster space?
- When we normalized our coordinates to be in the range [0,1], we still need actual coordinates. To do that, we simply multiply the normalized coordinates by the width or height (x * width, y * height). Now, our coordinates are in raster space

* Footnotes

[fn:2] Run the command "M-x org-display-inline-images" to display the image

[fn:1] Taken from https://www.scratchapixel.com/lessons/3d-basic-rendering/introduction-to-ray-tracing/implementing-the-raytracing-algorithm
